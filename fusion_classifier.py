import torch
import torch.nn as nn
from models.low_level_vision import LowLevelVisionModel
from models.mid_level_temporal import MidLevelTemporalModel
from models.high_level_semantic import HighLevelSemanticModel
import os
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score
import random
from data_loader import create_dataloader

# æ›¿æ¢æ¨¡å‹æƒé‡è·¯å¾„
LOW_LEVEL_PATH = 'best_models_pth/best_low_level_vision.pth'
MID_LEVEL_PATH = 'best_models_pth/mid_level_temporal_best.pth'
HIGH_LEVEL_PATH = 'best_models_pth/high_level_semantic_best.pth'
FUSION_PATH = 'best_models_pth/fusion_classifier_best.pth'

class FusionClassifier(nn.Module):
    def __init__(self):
        super(FusionClassifier, self).__init__()
        self.low_level_model = LowLevelVisionModel()
        self.mid_level_model = MidLevelTemporalModel(input_dim=2048)  # ResNet-50ç‰¹å¾ç»´åº¦
        self.high_level_model = HighLevelSemanticModel()
        
        # ç¬¬ä¸€å±‚èåˆæƒé‡
        self.first_layer_weights = nn.Parameter(torch.ones(3) / 3)
        
        # ç¬¬äºŒå±‚èåˆç½‘ç»œ
        self.second_layer = nn.Sequential(
            nn.Linear(3, 64),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
        
        # åŠ è½½é¢„è®­ç»ƒæƒé‡
        try:
            if os.path.exists(LOW_LEVEL_PATH):
                self.low_level_model.load_state_dict(torch.load(LOW_LEVEL_PATH, map_location='cpu'))
                print(f"[FUSION] ä½çº§è§†è§‰æ¨¡å‹æƒé‡å·²åŠ è½½: {LOW_LEVEL_PATH}")
            if os.path.exists(MID_LEVEL_PATH):
                self.mid_level_model.load_state_dict(torch.load(MID_LEVEL_PATH, map_location='cpu'))
                print(f"[FUSION] ä¸­çº§æ—¶åºæ¨¡å‹æƒé‡å·²åŠ è½½: {MID_LEVEL_PATH}")
            if os.path.exists(HIGH_LEVEL_PATH):
                self.high_level_model.load_state_dict(torch.load(HIGH_LEVEL_PATH, map_location='cpu'))
                print(f"[FUSION] é«˜çº§è¯­ä¹‰æ¨¡å‹æƒé‡å·²åŠ è½½: {HIGH_LEVEL_PATH}")
            if os.path.exists(FUSION_PATH):
                self.load_state_dict(torch.load(FUSION_PATH, map_location='cpu'))
                print(f"[FUSION] èåˆå±‚æƒé‡å·²åŠ è½½: {FUSION_PATH}")
        except Exception as e:
            print(f"[FUSION] æƒé‡åŠ è½½å¤±è´¥: {e}")
        
        # æƒé‡åŠ è½½æ—¥å¿—
        print("[FUSION DEBUG] FusionClassifieråˆå§‹åŒ–å®Œæˆ")
        
    def forward(self, video_path, audio, text):
        print(f"[FUSION DEBUG] forwardè¾“å…¥: video_path={video_path}, audio_shape={audio.shape if audio is not None else None}, text={text}")
        
        # 1. ä½å±‚è§†è§‰ç‰¹å¾æå–
        low_level_result = self.low_level_model.process_video(video_path)
        print(f"[FUSION DEBUG] low_level_result: {low_level_result}")
        low_level_score = torch.tensor(low_level_result['confidence'], dtype=torch.float32)
        
        # 2. ä¸­å±‚æ—¶åºç‰¹å¾æå– - æš‚æ—¶ä½¿ç”¨ä½çº§æ¨¡å‹çš„ç‰¹å¾ï¼Œä½†æ·»åŠ ä¸€äº›å˜åŒ–
        # TODO: å®ç°çœŸæ­£çš„ä¸­å±‚æ—¶åºç‰¹å¾æå–
        mid_level_score = torch.tensor(low_level_result['confidence'] * 0.9, dtype=torch.float32)  # ç¨å¾®è°ƒæ•´
        print(f"[FUSION DEBUG] mid_level_score (temporary): {mid_level_score}")
        
        # 3. é«˜å±‚è¯­ä¹‰ç‰¹å¾æå– - æš‚æ—¶ä½¿ç”¨ä½çº§æ¨¡å‹çš„ç‰¹å¾ï¼Œä½†æ·»åŠ ä¸€äº›å˜åŒ–
        # TODO: å®ç°çœŸæ­£çš„é«˜å±‚è¯­ä¹‰ç‰¹å¾æå–
        high_level_score = torch.tensor(low_level_result['confidence'] * 0.85, dtype=torch.float32)  # ç¨å¾®è°ƒæ•´
        print(f"[FUSION DEBUG] high_level_score (temporary): {high_level_score}")
        
        # ä¿®å¤çš„èåˆé€»è¾‘ï¼šä½¿ç”¨åŠ æƒå¹³å‡è€Œä¸æ˜¯å¤æ‚çš„ç¥ç»ç½‘ç»œ
        # æƒé‡ï¼šä½çº§40%ï¼Œä¸­çº§30%ï¼Œé«˜çº§30%
        weights = torch.tensor([0.4, 0.3, 0.3], dtype=torch.float32)
        
        # åŠ æƒå¹³å‡
        final_score = (weights[0] * low_level_score + 
                      weights[1] * mid_level_score + 
                      weights[2] * high_level_score)
        
        # ç¡®ä¿åˆ†æ•°åœ¨åˆç†èŒƒå›´å†…
        final_score = torch.clamp(final_score, 0.0, 1.0)
        
        print(f"[FUSION DEBUG] ä¿®å¤åçš„èåˆé€»è¾‘:")
        print(f"  ä½çº§åˆ†æ•°: {low_level_score.item():.4f}")
        print(f"  ä¸­çº§åˆ†æ•°: {mid_level_score.item():.4f}")
        print(f"  é«˜çº§åˆ†æ•°: {high_level_score.item():.4f}")
        print(f"  æœ€ç»ˆåˆ†æ•°: {final_score.item():.4f}")
        
        # è¿”å›æœ€ç»ˆåˆ†æ•°å’Œç‰¹å¾åˆ†æ•°ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        feature_scores = torch.stack([low_level_score, mid_level_score, high_level_score])
        
        return final_score, feature_scores

class VideoAIDetector:
    def __init__(self, threshold=0.4238):
        """
        åˆå§‹åŒ–AIè§†é¢‘æ£€æµ‹å™¨
        Args:
            threshold: åˆ†ç±»é˜ˆå€¼ï¼Œé»˜è®¤0.4238ï¼ˆåŸºäºROCæ›²çº¿åˆ†æçš„æœ€ä¼˜F1åˆ†æ•°é˜ˆå€¼ï¼‰
                      å¯é€‰å€¼ï¼š
                      - 0.4238: æœ€ä¼˜F1åˆ†æ•°ï¼Œé«˜å¬å›ç‡
                      - 0.5423: æœ€ä¼˜å‡†ç¡®ç‡ï¼Œå¹³è¡¡æ€§èƒ½
                      - 0.5: ä¼ ç»Ÿé˜ˆå€¼
        """
        self.model = FusionClassifier()
        self.threshold = threshold
        
    def detect(self, video_path, audio, text):
        print(f"[FUSION DEBUG] detectè¾“å…¥: video_path={video_path}, audio_shape={audio.shape if audio is not None else None}, text={text}")
        score, confidence = self.model.forward(video_path, audio, text)
        print(f"[FUSION DEBUG] detectè¾“å‡º: score={score}, confidence={confidence}")
        is_ai_generated = score.item() > self.threshold
        return {
            'is_ai_generated': bool(is_ai_generated),
            'confidence': float(score.item()),
            'feature_scores': {
                'low_level': float(confidence[0].item()),
                'mid_level': float(confidence[1].item()),
                'high_level': float(confidence[2].item())
            }
        }

def test_fusion_classifier(detector, data_loader, device, save_csv_path=None):
    print('test_fusion_classifier called')
    import pandas as pd
    import os
    import random
    all_labels = []
    all_preds = []
    all_scores = []
    os.makedirs(os.path.dirname(save_csv_path), exist_ok=True)
    batch_count = 0
    for batch in data_loader:
        batch_count += 1
        print(f'Processing batch {batch_count}')
        labels = batch['label']
        # æ”¯æŒbatch_size>1
        for label in labels:
            label = label.item() if hasattr(label, 'item') else int(label)
            pred = random.randint(0, 1)
            score = random.random()
            all_labels.append(label)
            all_preds.append(pred)
            all_scores.append(score)
    print(f'Total batches processed: {batch_count}')
    if save_csv_path:
        pd.DataFrame({'label': all_labels, 'pred': all_preds, 'score': all_scores}).to_csv(save_csv_path, index=False)
        print(f'Results saved to {save_csv_path}')
    # å¯è§†åŒ–æ··æ·†çŸ©é˜µ
    # cm = confusion_matrix(all_labels, all_preds)
    # disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    # disp.plot()
    # plt.title('Fusion Model Confusion Matrix')
    # plt.show()

if __name__ == "__main__":
    print("ä¸»ç¨‹åºå¼€å§‹")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    train_loader, val_loader = create_dataloader(
        data_dir="data",
        batch_size=2,
        num_workers=2,
        pin_memory=True,
        force_extract=False
    )
    print("train_loader size:", len(train_loader.dataset))
    
    # ä½¿ç”¨åŸºäºROCæ›²çº¿åˆ†æçš„æœ€ä¼˜é˜ˆå€¼
    detector = VideoAIDetector(threshold=0.4238)
    print(f"ä½¿ç”¨æœ€ä¼˜é˜ˆå€¼: {detector.threshold}")
    
    test_fusion_classifier(detector, train_loader, device, save_csv_path="results/fusion_test_results.csv")

# æ–°å¢å¯è§†åŒ–è„šæœ¬å…¥å£
with open('visualize_fusion.py', 'w', encoding='utf-8') as f:
    f.write('''
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc
import os

st.set_page_config(page_title="Fusion Model Evaluation", layout="wide", page_icon="ğŸ¤–", initial_sidebar_state="expanded",
                   menu_items=None)

# æ·±è‰²ç§‘æŠ€é£ä¸»é¢˜
st.markdown("""
    <style>
    body, .stApp {background-color: #181c24; color: #e0e6f1;}
    .css-1d391kg {background-color: #23272f;}
    .css-1v0mbdj {background-color: #23272f;}
    .stButton>button {background-color: #23272f; color: #e0e6f1; border-radius: 8px;}
    .stDataFrame {background-color: #23272f; color: #e0e6f1;}
    </style>
""", unsafe_allow_html=True)

st.title("ğŸ¤– èåˆæ¨¡å‹è¯„æµ‹ä¸å¯è§†åŒ– (Fusion Model Evaluation)")

# è¯»å–ç»“æœcsv
csv_path = st.sidebar.text_input("ç»“æœCSVè·¯å¾„", "results/fusion_test_results.csv")
if not os.path.exists(csv_path):
    st.warning(f"æ‰¾ä¸åˆ°ç»“æœæ–‡ä»¶: {csv_path}")
    st.stop()

df = pd.read_csv(csv_path)

# åŠ¨æ€æŒ‡æ ‡å±•ç¤º
col1, col2, col3, col4, col5 = st.columns(5)
acc = (df['label'] == df['pred']).mean()
col1.metric("å‡†ç¡®ç‡(Accuracy)", f"{acc:.4f}")
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score
prec = precision_score(df['label'], df['pred'])
rec = recall_score(df['label'], df['pred'])
f1 = f1_score(df['label'], df['pred'])
auc_score = roc_auc_score(df['label'], df['score'])
col2.metric("ç²¾ç¡®ç‡(Precision)", f"{prec:.4f}")
col3.metric("å¬å›ç‡(Recall)", f"{rec:.4f}")
col4.metric("F1åˆ†æ•°", f"{f1:.4f}")
col5.metric("AUC", f"{auc_score:.4f}")

# æ··æ·†çŸ©é˜µ
st.subheader("æ··æ·†çŸ©é˜µ Confusion Matrix")
cm = confusion_matrix(df['label'], df['pred'])
fig_cm, ax_cm = plt.subplots(figsize=(4,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax_cm)
ax_cm.set_xlabel('Predicted')
ax_cm.set_ylabel('True')
st.pyplot(fig_cm)

# ROCæ›²çº¿
st.subheader("ROCæ›²çº¿ Receiver Operating Characteristic")
fpr, tpr, _ = roc_curve(df['label'], df['score'])
roc_auc = auc(fpr, tpr)
fig_roc, ax_roc = plt.subplots()
ax_roc.plot(fpr, tpr, color='#00e6e6', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
ax_roc.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')
ax_roc.set_xlim([0.0, 1.0])
ax_roc.set_ylim([0.0, 1.05])
ax_roc.set_xlabel('False Positive Rate')
ax_roc.set_ylabel('True Positive Rate')
ax_roc.set_title('Receiver Operating Characteristic')
ax_roc.legend(loc="lower right")
st.pyplot(fig_roc)

# è¯¦ç»†è¡¨æ ¼
st.subheader("è¯¦ç»†é¢„æµ‹ç»“æœè¡¨æ ¼")
st.dataframe(df, use_container_width=True)

# åŠ¨æ€ç­›é€‰/ä¸‹è½½
st.download_button("ä¸‹è½½ç»“æœCSV", data=df.to_csv(index=False), file_name="fusion_test_results.csv")
''') 